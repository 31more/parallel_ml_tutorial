{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Predictive Modeling with heterogeneous data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Monkeypatching scikit-learn embedded joblib\n"
       ]
      }
     ],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/images/predictive_modeling_data_flow.png\">"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading tabular data from the Titanic kaggle challenge in a pandas Data Frame"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us have a look at the Titanic dataset from the Kaggle Getting Started challenge at:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted\n",
      "\n",
      "We can load the CSV file as a pandas data frame in one line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!curl -s https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv | head -5\n",
      "with open('titanic_train.csv', 'r') as f:\n",
      "    for i, line in zip(range(5), f):\n",
      "        print(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
        "\n",
        "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n",
        "\n",
        "2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n",
        "\n",
        "3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n",
        "\n",
        "4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = pd.read_csv('https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv')\n",
      "data = pd.read_csv('titanic_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas data frames have a HTML table representation in the IPython notebook. Let's have a look at the first 5 rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>        A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>         PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td>  C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>                            Heikkinen, Miss. Laina</td>\n",
        "      <td> female</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> STON/O2. 3101282</td>\n",
        "      <td>  7.9250</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td> female</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>           113803</td>\n",
        "      <td> 53.1000</td>\n",
        "      <td> C123</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                          Allen, Mr. William Henry</td>\n",
        "      <td>   male</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>           373450</td>\n",
        "      <td>  8.0500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "2            3         1       3   \n",
        "3            4         1       1   \n",
        "4            5         0       3   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "2                             Heikkinen, Miss. Laina  female   26      0   \n",
        "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
        "4                           Allen, Mr. William Henry    male   35      0   \n",
        "\n",
        "   Parch            Ticket     Fare Cabin Embarked  \n",
        "0      0         A/5 21171   7.2500   NaN        S  \n",
        "1      0          PC 17599  71.2833   C85        C  \n",
        "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3      0            113803  53.1000  C123        S  \n",
        "4      0            373450   8.0500   NaN        S  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "PassengerId    891\n",
        "Survived       891\n",
        "Pclass         891\n",
        "Name           891\n",
        "Sex            891\n",
        "Age            714\n",
        "SibSp          891\n",
        "Parch          891\n",
        "Ticket         891\n",
        "Fare           891\n",
        "Cabin          204\n",
        "Embarked       889\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data frame has 891 rows. Some passengers have missing information though: in particular Age and Cabin info can be missing. The meaning of the columns is explained on the challenge website:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted/data\n",
      "\n",
      "A data frame can be converted into a numpy array by calling the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(data.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['PassengerId',\n",
        " 'Survived',\n",
        " 'Pclass',\n",
        " 'Name',\n",
        " 'Sex',\n",
        " 'Age',\n",
        " 'SibSp',\n",
        " 'Parch',\n",
        " 'Ticket',\n",
        " 'Fare',\n",
        " 'Cabin',\n",
        " 'Embarked']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(891, 12)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
        "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
        "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
        "       ..., \n",
        "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
        "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
        "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However this cannot be directly fed to a scikit-learn model:\n",
      "\n",
      "\n",
      "- the target variable (survival) is mixed with the input data\n",
      "\n",
      "- some attribute such as unique ids have no predictive values for the task\n",
      "\n",
      "- the values are heterogeneous (string labels for categories, integers and floating point numbers)\n",
      "\n",
      "- some attribute values are missing (nan: \"not a number\")"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicting survival"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of the challenge is to predict whether a passenger has survived from others known attribute. Let us have a look at the `Survived` columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survived_column = data['Survived']\n",
      "survived_column.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`data.Survived` is an instance of the pandas `Series` class with an integer dtype:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(survived_column)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "pandas.core.series.Series"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `data` object is an instance pandas `DataFrame` class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Series` can be seen as homegeneous, 1D columns. `DataFrame` instances are heterogenous collections of columns with the same length.\n",
      "\n",
      "The original data frame can be aggregated by counting rows for each possible value of the `Survived` column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.groupby('Survived').count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Survived</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 424</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td> 549</td>\n",
        "      <td>  68</td>\n",
        "      <td> 549</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 290</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 342</td>\n",
        "      <td> 136</td>\n",
        "      <td> 340</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "          PassengerId  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
        "Survived                                                                    \n",
        "0                 549     549   549  549  424    549    549     549   549   \n",
        "1                 342     342   342  342  290    342    342     342   342   \n",
        "\n",
        "          Cabin  Embarked  \n",
        "Survived                   \n",
        "0            68       549  \n",
        "1           136       340  "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(survived_column == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.61616161616161613"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this the subset of the full passengers list, about 2/3 perished in the event. So if we are to build a predictive model from this data, a baseline model to compare the performance to would be to always predict death. Such a constant model would reach around 62% predictive accuracy (which is higher than predicting at random):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas `Series` instances can be converted to regular 1D numpy arrays by using the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = survived_column.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([0, 1, 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training a predictive model on numerical features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` estimators all work with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
      "\n",
      "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "numerical_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately some passengers do not have age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       714\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use pandas `fillna` method to input the median age for those passengers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "median_features = numerical_features.dropna().median()\n",
      "median_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "Fare      15.7417\n",
        "Pclass     2.0000\n",
        "Age       28.0000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features = numerical_features.fillna(median_features)\n",
      "imputed_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array = imputed_features.values\n",
      "features_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([[  7.25  ,   3.    ,  22.    ],\n",
        "       [ 71.2833,   1.    ,  38.    ],\n",
        "       [  7.925 ,   3.    ,  26.    ],\n",
        "       ..., \n",
        "       [ 23.45  ,   3.    ,  28.    ],\n",
        "       [ 30.    ,   1.    ,  26.    ],\n",
        "       [  7.75  ,   3.    ,  32.    ]])"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "dtype('float64')"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take the 80% of the data for training a first model and keep 20% for computing is generalization score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "(712, 3)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "(179, 3)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "(712,)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(179,)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a simple model from sklearn, namely `LogisticRegression`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "logreg.fit(features_train, target_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
        "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "          verbose=0)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted = logreg.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "accuracy_score(target_test, target_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This first model has around 73% accuracy: this is better than our baseline that always predicts death."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model evaluation and interpretation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpreting linear model weights"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = numerical_features.columns\n",
      "feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "Index(['Fare', 'Pclass', 'Age'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([[ 0.0043996 , -0.80916725, -0.03348064]])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(len(feature_names))\n",
      "plt.bar(x, logreg.coef_.ravel())\n",
      "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEJCAYAAABv6GdPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10cf024e0>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, survival is slightly positively linked with Fare (the higher the fare, the higher the likelyhood the model will predict survival) while passenger from first class and lower ages are predicted to survive more often than older people from the 3rd class.\n",
      "\n",
      "First-class cabins were closer to the lifeboats and children and women reportedly had the priority. Our model seems to capture that historical data. We will see later if the sex of the passenger can be used as an informative predictor to increase the predictive accuracy of the model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Alternative evaluation metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to see the details of the false positive and false negative errors by computing the confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "cm = confusion_matrix(target_test, target_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The true labeling are seen as the rows and the predicted labels are the columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_confusion(cm):\n",
      "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.binary)\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.set_cmap('Blues')\n",
      "    plt.colorbar()\n",
      "\n",
      "    target_names = ['not survived', 'survived']\n",
      "\n",
      "    tick_marks = np.arange(len(target_names))\n",
      "    plt.xticks(tick_marks, target_names, rotation=60)\n",
      "    plt.yticks(tick_marks, target_names)\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    # Convenience function to adjust plot parameters for a clear layout.\n",
      "    plt.tight_layout()\n",
      "    \n",
      "plot_confusion(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAEaCAYAAACB7ptqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10cfb4470>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can normalize the number of prediction by dividing by the total number of true \"survived\" and \"not survived\" to compute false and true positive rates for survival (in the second column of the confusion matrix)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cm.astype(np.float64) / cm.sum(axis=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.89090909  0.17391304]\n",
        " [ 0.32727273  0.47826087]]\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can therefore observe that the fact that the target classes are not balanced in the dataset makes the accuracy score not very informative.\n",
      "\n",
      "scikit-learn provides alternative classification metrics to evaluate models performance on imbalanced data such as precision, recall and f1 score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.73      0.89      0.80       110\n",
        "    survived       0.73      0.48      0.58        69\n",
        "\n",
        " avg / total       0.73      0.73      0.72       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to quantify the quality of a binary classifier on imbalanced data is to compute the precision, recall and f1-score of a model (at the default fixed decision threshold of 0.5)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the posterior probability of the outcome given the input features using the `predict_proba` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_proba = logreg.predict_proba(features_test)\n",
      "target_predicted_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([[ 0.75263264,  0.24736736],\n",
        "       [ 0.75824771,  0.24175229],\n",
        "       [ 0.58542437,  0.41457563],\n",
        "       [ 0.25224882,  0.74775118],\n",
        "       [ 0.75817844,  0.24182156]])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
      "\n",
      "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(target_test, target_predicted_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(target_test, target_predicted_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10ca85ac8>"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the area under ROC curve is 0.756 which is very similar to the accuracy (0.732). However the ROC-AUC score of a random model is expected to 0.5 on average while the accuracy score of a random model depends on the class imbalance of the data. ROC-AUC can be seen as a way to callibrate the predictive accuracy of a model against class imbalance."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We previously decided to randomly split the data to evaluate the model on 20% of held-out data. However the location randomness of the split might have a significant impact in the estimated accuracy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=1)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "0.67039106145251393"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=2)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "0.66480446927374304"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So instead of using a single train / test split, we can use a group of them and compute the min, max and mean scores as an estimation of the real test score while not underestimating the variability:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(logreg, features_array, target, cv=5)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "array([ 0.63128492,  0.68715084,  0.70224719,  0.73033708,  0.71751412])"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "(0.63128491620111726, 0.69370682962933028, 0.7303370786516854)"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`cross_val_score` reports accuracy by default be it can also be used to report other performance metrics such as ROC-AUC or f1-score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(logreg, features_array, target, cv=5,\n",
      "                         scoring='roc_auc')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "(0.61093544137022393, 0.72123181651091728, 0.78776737967914434)"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Compute cross-validated scores for other classification metrics ('precision', 'recall', 'f1', 'accuracy'...).\n",
      "\n",
      "- Change the number of cross-validation folds between 3 and 10: what is the impact on the mean score? on the processing time?\n",
      "\n",
      "Hints:\n",
      "\n",
      "The list of classification metrics is available in the online documentation:\n",
      "\n",
      "  http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\n",
      "  \n",
      "You can use the `%%time` cell magic on the first line of an IPython cell to measure the time of the execution of the cell. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "More feature engineering and richer models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us now try to build richer models by including more features as potential predictors for our model.\n",
      "\n",
      "Categorical variables such as `data.Embarked` or `data.Sex` can be converted as boolean indicators features also known as dummy variables or one-hot-encoded features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.get_dummies(data.Sex, prefix='Sex').head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Sex_male</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "   Sex_female  Sex_male\n",
        "0           0         1\n",
        "1           1         0\n",
        "2           1         0\n",
        "3           1         0\n",
        "4           0         1"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.get_dummies(data.Embarked, prefix='Embarked').head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "   Embarked_C  Embarked_Q  Embarked_S\n",
        "0           0           0           1\n",
        "1           1           0           0\n",
        "2           0           0           1\n",
        "3           0           0           1\n",
        "4           0           0           1"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can combine those new numerical features with the previous features using `pandas.concat` along `axis=1`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features = pd.concat([data.get(['Fare', 'Pclass', 'Age']),\n",
      "                           pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                           pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
      "                          axis=1)\n",
      "rich_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Sex_male</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
        "0   7.2500       3   22           0         1           0           0   \n",
        "1  71.2833       1   38           1         0           1           0   \n",
        "2   7.9250       3   26           1         0           0           0   \n",
        "3  53.1000       1   35           1         0           0           0   \n",
        "4   8.0500       3   35           0         1           0           0   \n",
        "\n",
        "   Embarked_S  \n",
        "0           1  \n",
        "1           0  \n",
        "2           1  \n",
        "3           1  \n",
        "4           1  "
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By construction the new `Sex_male` feature is redundant with `Sex_female`. Let us drop it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features_no_male = rich_features.drop('Sex_male', 1)\n",
      "rich_features_no_male.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S\n",
        "0   7.2500       3   22           0           0           0           1\n",
        "1  71.2833       1   38           1           1           0           0\n",
        "2   7.9250       3   26           1           0           0           1\n",
        "3  53.1000       1   35           1           0           0           1\n",
        "4   8.0500       3   35           0           0           0           1"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us not forget to imput the median age for passengers without age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features_final = rich_features_no_male.fillna(rich_features_no_male.dropna().median())\n",
      "rich_features_final.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 1</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 3</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 1</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 3</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S\n",
        "0   7.2500       3   22           0           0           0           1\n",
        "1  71.2833       1   38           1           1           0           0\n",
        "2   7.9250       3   26           1           0           0           1\n",
        "3  53.1000       1   35           1           0           0           1\n",
        "4   8.0500       3   35           0           0           0           1"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can finally cross-validate a logistic regression model on this new data an observe that the mean score has significantly increased:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "scores = cross_val_score(logreg, rich_features_final, target, cv=5, scoring='accuracy')\n",
      "print(\"Logistic Regression CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic Regression CV scores:\n",
        "min: 0.770, mean: 0.786, max: 0.810\n",
        "CPU times: user 34.8 ms, sys: 9.03 ms, total: 43.8 ms\n",
        "Wall time: 23.4 ms\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- change the value of the parameter `C`. Does it have an impact on the score?\n",
      "\n",
      "- fit a new instance of the logistic regression model on the full dataset.\n",
      "\n",
      "- plot the weights for the features of this newly fitted logistic regression model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04A_plot_logistic_regression_weights.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training Non-linear models: ensembles of randomized trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` also implement non linear models that are known to perform very well for data-science projects where datasets have not too many features (e.g. less than 5000).\n",
      "\n",
      "In particular let us have a look at Random Forests and Gradient Boosted Trees:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "scores = cross_val_score(rf, rich_features_final, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "print(\"Random Forest CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest CV scores:\n",
        "min: 0.782, mean: 0.806, max: 0.843\n",
        "CPU times: user 113 ms, sys: 22.6 ms, total: 136 ms\n",
        "Wall time: 627 ms\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                subsample=.8, max_features=.5)\n",
      "scores = cross_val_score(gb, rich_features_final, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "print(\"Gradient Boosted Trees CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Gradient Boosted Trees CV scores:\n",
        "min: 0.788, mean: 0.818, max: 0.853\n",
        "CPU times: user 65.9 ms, sys: 21.9 ms, total: 87.8 ms\n",
        "Wall time: 363 ms\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both models seem to do slightly better than the logistic regression model on this data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Change the value of the learning_rate and other `GradientBoostingClassifier` parameter, can you get a better mean score?\n",
      "\n",
      "- Would treating the `PClass` variable as categorical improve the models performance?\n",
      "\n",
      "- Find out which predictor variables (features) are the most informative for those models.\n",
      "\n",
      "Hints:\n",
      "\n",
      "Fitted ensembles of trees have `feature_importances_` attribute that can be used similarly to the `coef_` attribute of linear models."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04B_more_categorical_variables.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04C_feature_importance.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automated parameter tuning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of changing the value of the learning rate manually and re-running the cross-validation, we can find the best values for the parameters automatically (assuming we are ready to wait):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, subsample=.8)\n",
      "\n",
      "params = {\n",
      "    'learning_rate': [0.05, 0.1, 0.5],\n",
      "    'max_features': [0.5, 1],\n",
      "    'max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(gb, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(rich_features_final, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 654 ms, sys: 35.1 ms, total: 689 ms\n",
        "Wall time: 4.94 s\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us sort the models by mean validation score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(gs.grid_scores_, key=lambda x: x.mean_validation_score, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "[mean: 0.87738, std: 0.02585, params: {'max_features': 0.5, 'max_depth': 4, 'learning_rate': 0.05},\n",
        " mean: 0.87501, std: 0.02893, params: {'max_features': 0.5, 'max_depth': 4, 'learning_rate': 0.1},\n",
        " mean: 0.87471, std: 0.02613, params: {'max_features': 1, 'max_depth': 5, 'learning_rate': 0.05},\n",
        " mean: 0.87220, std: 0.02916, params: {'max_features': 0.5, 'max_depth': 3, 'learning_rate': 0.1},\n",
        " mean: 0.87163, std: 0.02269, params: {'max_features': 0.5, 'max_depth': 5, 'learning_rate': 0.1},\n",
        " mean: 0.87077, std: 0.02775, params: {'max_features': 0.5, 'max_depth': 5, 'learning_rate': 0.05},\n",
        " mean: 0.86827, std: 0.02773, params: {'max_features': 0.5, 'max_depth': 3, 'learning_rate': 0.05},\n",
        " mean: 0.86806, std: 0.02180, params: {'max_features': 1, 'max_depth': 3, 'learning_rate': 0.1},\n",
        " mean: 0.86705, std: 0.02399, params: {'max_features': 1, 'max_depth': 4, 'learning_rate': 0.1},\n",
        " mean: 0.86616, std: 0.02325, params: {'max_features': 1, 'max_depth': 4, 'learning_rate': 0.05},\n",
        " mean: 0.86611, std: 0.02744, params: {'max_features': 1, 'max_depth': 5, 'learning_rate': 0.1},\n",
        " mean: 0.86471, std: 0.03106, params: {'max_features': 1, 'max_depth': 3, 'learning_rate': 0.5},\n",
        " mean: 0.86013, std: 0.02082, params: {'max_features': 1, 'max_depth': 3, 'learning_rate': 0.05},\n",
        " mean: 0.85898, std: 0.02162, params: {'max_features': 0.5, 'max_depth': 4, 'learning_rate': 0.5},\n",
        " mean: 0.85745, std: 0.01972, params: {'max_features': 0.5, 'max_depth': 3, 'learning_rate': 0.5},\n",
        " mean: 0.85526, std: 0.02088, params: {'max_features': 1, 'max_depth': 4, 'learning_rate': 0.5},\n",
        " mean: 0.84644, std: 0.01886, params: {'max_features': 0.5, 'max_depth': 5, 'learning_rate': 0.5},\n",
        " mean: 0.84630, std: 0.01856, params: {'max_features': 1, 'max_depth': 5, 'learning_rate': 0.5}]"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "0.87737565517300375"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{'max_features': 0.5, 'max_depth': 4, 'learning_rate': 0.05}"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should note that the mean scores are very close to one another and almost always within one standard deviation of one another. This means that all those parameters are quite reasonable. The only parameter of importance seems to be the `learning_rate`: 0.5 seems to be a bit too high."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Avoiding data snooping with pipelines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When doing imputation in pandas, prior to computing the train test split we use data from the test to improve the accuracy of the median value that we impute on the training set. This is actually cheating. To avoid this we should compute the median of the features on the training fold and use that median value to do the imputation both on the training and validation fold for a given CV split.\n",
      "\n",
      "To do this we can prepare the features as previously but without the imputation: we just replace missing values by the -1 marker value:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = pd.concat([data.get(['Fare', 'Age']),\n",
      "                      pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                      pd.get_dummies(data.Pclass, prefix='Pclass'),\n",
      "                      pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
      "                     axis=1)\n",
      "features = features.drop('Sex_male', 1)\n",
      "\n",
      "# Because of the following bug we cannot use NaN as the missing\n",
      "# value marker, use a negative value as marker instead:\n",
      "# https://github.com/scikit-learn/scikit-learn/issues/3044\n",
      "features = features.fillna(-1)\n",
      "features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Pclass_1</th>\n",
        "      <th>Pclass_2</th>\n",
        "      <th>Pclass_3</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  7.2500</td>\n",
        "      <td> 22</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 71.2833</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>  7.9250</td>\n",
        "      <td> 26</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 53.1000</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>  8.0500</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "      Fare  Age  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  \\\n",
        "0   7.2500   22           0         0         0         1           0   \n",
        "1  71.2833   38           1         1         0         0           1   \n",
        "2   7.9250   26           1         0         0         1           0   \n",
        "3  53.1000   35           1         1         0         0           0   \n",
        "4   8.0500   35           0         0         0         1           0   \n",
        "\n",
        "   Embarked_Q  Embarked_S  \n",
        "0           0           1  \n",
        "1           0           0  \n",
        "2           0           1  \n",
        "3           0           1  \n",
        "4           0           1  "
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use the `Imputer` transformer of scikit-learn to find the median value on the training set and apply it on missing values of both the training set and the test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(features.values, target, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import Imputer\n",
      "\n",
      "imputer = Imputer(strategy='median', missing_values=-1)\n",
      "\n",
      "imputer.fit(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "Imputer(axis=0, copy=True, missing_values=-1, strategy='median', verbose=0)"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The median age computed on the training set is stored in the `statistics_` attribute."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputer.statistics_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "array([ 14.5,  29. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   1. ])"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imputation can now happen by calling  the transform method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_imputed = imputer.transform(X_train)\n",
      "X_test_imputed = imputer.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_train == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_train_imputed == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_test == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_test_imputed == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use a pipeline that wraps an imputer transformer and the classifier itself:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "imputer = Imputer(strategy='median', missing_values=-1)\n",
      "\n",
      "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                        subsample=.8, max_features=.5)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', classifier),\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, features.values, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy', )\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.798882681564 0.822727284011 0.848314606742\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The mean cross-validation is slightly lower than we used the imputation on the whole data as we did earlier although not by much. This means that in this case the data-snooping was not really helping the model cheat by much.\n",
      "\n",
      "Let us re-run the grid search, this time on the pipeline. Note that thanks to the pipeline structure we can optimize the interaction of the imputation method with the parameters of the downstream classifier without cheating:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "params = {\n",
      "    'imp__strategy': ['mean', 'median'],\n",
      "    'clf__max_features': [0.5, 1],\n",
      "    'clf__max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(pipeline, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 428 ms, sys: 30.5 ms, total: 458 ms\n",
        "Wall time: 3.1 s\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(gs.grid_scores_, key=lambda x: x.mean_validation_score, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "[mean: 0.87128, std: 0.02162, params: {'clf__max_depth': 4, 'imp__strategy': 'mean', 'clf__max_features': 0.5},\n",
        " mean: 0.86788, std: 0.02825, params: {'clf__max_depth': 4, 'imp__strategy': 'median', 'clf__max_features': 0.5},\n",
        " mean: 0.86777, std: 0.02502, params: {'clf__max_depth': 3, 'imp__strategy': 'median', 'clf__max_features': 0.5},\n",
        " mean: 0.86544, std: 0.02755, params: {'clf__max_depth': 5, 'imp__strategy': 'mean', 'clf__max_features': 0.5},\n",
        " mean: 0.86479, std: 0.02375, params: {'clf__max_depth': 3, 'imp__strategy': 'mean', 'clf__max_features': 0.5},\n",
        " mean: 0.86392, std: 0.02449, params: {'clf__max_depth': 3, 'imp__strategy': 'median', 'clf__max_features': 1},\n",
        " mean: 0.86312, std: 0.02858, params: {'clf__max_depth': 4, 'imp__strategy': 'median', 'clf__max_features': 1},\n",
        " mean: 0.86129, std: 0.03032, params: {'clf__max_depth': 4, 'imp__strategy': 'mean', 'clf__max_features': 1},\n",
        " mean: 0.86052, std: 0.02521, params: {'clf__max_depth': 5, 'imp__strategy': 'median', 'clf__max_features': 0.5},\n",
        " mean: 0.86001, std: 0.02579, params: {'clf__max_depth': 5, 'imp__strategy': 'mean', 'clf__max_features': 1},\n",
        " mean: 0.85938, std: 0.02655, params: {'clf__max_depth': 3, 'imp__strategy': 'mean', 'clf__max_features': 1},\n",
        " mean: 0.85930, std: 0.02699, params: {'clf__max_depth': 5, 'imp__strategy': 'median', 'clf__max_features': 1}]"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "0.87127536946854545"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(y_test, gs.predict_proba(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10d2990f0>"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "{'clf__max_depth': 4, 'imp__strategy': 'mean', 'clf__max_features': 0.5}"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this search we can conclude that the imputation by the 'mean' strategy is generally a slightly better imputation strategy when training a GBRT model on this data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further integrating sklearn and pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper tool for better sklearn / pandas integration: https://github.com/paulgb/sklearn-pandas by making it possible to embed the feature construction from the raw dataframe directly inside a pipeline."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Credits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thanks to:\n",
      "\n",
      "- Kaggle for setting up the Titanic challenge.\n",
      "\n",
      "- This blog post by Philippe Adjiman for inspiration:\n",
      "\n",
      "http://www.philippeadjiman.com/blog/2013/09/12/a-data-science-exploration-from-the-titanic-in-r/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    }
   ],
   "metadata": {}
  }
 ]
}