{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Predictive Modeling with heterogeneous data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/images/predictive_modeling_data_flow.png\">"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading tabular data from the Titanic kaggle challenge in a pandas Data Frame"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us have a look at the Titanic dataset from the Kaggle Getting Started challenge at:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted\n",
      "\n",
      "We can load the CSV file as a pandas data frame in one line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!curl -s https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv | head -5\n",
      "with open('titanic_train.csv', 'r') as f:\n",
      "    for i, line in zip(range(5), f):\n",
      "        print(line)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
        "\n",
        "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n",
        "\n",
        "2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n",
        "\n",
        "3,1,3,\"Heikkinen, Miss. Laina\",female,26,0,0,STON/O2. 3101282,7.925,,S\n",
        "\n",
        "4,1,1,\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",female,35,1,0,113803,53.1,C123,S\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data = pd.read_csv('https://dl.dropboxusercontent.com/u/5743203/data/titanic/titanic_train.csv')\n",
      "data = pd.read_csv('titanic_train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas data frames have a HTML table representation in the IPython notebook. Let's have a look at the first 5 rows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>Braund, Mr. Owen Harris</td>\n",
        "      <td>male</td>\n",
        "      <td>22</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>A/5 21171</td>\n",
        "      <td>7.2500</td>\n",
        "      <td>NaN</td>\n",
        "      <td>S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td>female</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>PC 17599</td>\n",
        "      <td>71.2833</td>\n",
        "      <td>C85</td>\n",
        "      <td>C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>3</td>\n",
        "      <td>1</td>\n",
        "      <td>3</td>\n",
        "      <td>Heikkinen, Miss. Laina</td>\n",
        "      <td>female</td>\n",
        "      <td>26</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>STON/O2. 3101282</td>\n",
        "      <td>7.9250</td>\n",
        "      <td>NaN</td>\n",
        "      <td>S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>4</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td>female</td>\n",
        "      <td>35</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>113803</td>\n",
        "      <td>53.1000</td>\n",
        "      <td>C123</td>\n",
        "      <td>S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>5</td>\n",
        "      <td>0</td>\n",
        "      <td>3</td>\n",
        "      <td>Allen, Mr. William Henry</td>\n",
        "      <td>male</td>\n",
        "      <td>35</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>373450</td>\n",
        "      <td>8.0500</td>\n",
        "      <td>NaN</td>\n",
        "      <td>S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "2            3         1       3   \n",
        "3            4         1       1   \n",
        "4            5         0       3   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "2                             Heikkinen, Miss. Laina  female   26      0   \n",
        "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
        "4                           Allen, Mr. William Henry    male   35      0   \n",
        "\n",
        "   Parch            Ticket     Fare Cabin Embarked  \n",
        "0      0         A/5 21171   7.2500   NaN        S  \n",
        "1      0          PC 17599  71.2833   C85        C  \n",
        "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3      0            113803  53.1000  C123        S  \n",
        "4      0            373450   8.0500   NaN        S  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "PassengerId    891\n",
        "Survived       891\n",
        "Pclass         891\n",
        "Name           891\n",
        "Sex            891\n",
        "Age            714\n",
        "SibSp          891\n",
        "Parch          891\n",
        "Ticket         891\n",
        "Fare           891\n",
        "Cabin          204\n",
        "Embarked       889\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data frame has 891 rows. Some passengers have missing information though: in particular Age and Cabin info can be missing. The meaning of the columns is explained on the challenge website:\n",
      "\n",
      "https://www.kaggle.com/c/titanic-gettingStarted/data\n",
      "\n",
      "A data frame can be converted into a numpy array by calling the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(data.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['PassengerId',\n",
        " 'Survived',\n",
        " 'Pclass',\n",
        " 'Name',\n",
        " 'Sex',\n",
        " 'Age',\n",
        " 'SibSp',\n",
        " 'Parch',\n",
        " 'Ticket',\n",
        " 'Fare',\n",
        " 'Cabin',\n",
        " 'Embarked']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(891, 12)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
        "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
        "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
        "       ..., \n",
        "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
        "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
        "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However this cannot be directly fed to a scikit-learn model:\n",
      "\n",
      "\n",
      "- the target variable (survival) is mixed with the input data\n",
      "\n",
      "- some attribute such as unique ids have no predictive values for the task\n",
      "\n",
      "- the values are heterogeneous (string labels for categories, integers and floating point numbers)\n",
      "\n",
      "- some attribute values are missing (nan: \"not a number\")"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Predicting survival"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of the challenge is to predict whether a passenger has survived from others known attribute. Let us have a look at the `Survived` columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "survived_column = data['Survived']\n",
      "survived_column.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`data.Survived` is an instance of the pandas `Series` class with an integer dtype:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(survived_column)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "pandas.core.series.Series"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `data` object is an instance pandas `DataFrame` class:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Series` can be seen as homegeneous, 1D columns. `DataFrame` instances are heterogenous collections of columns with the same length.\n",
      "\n",
      "The original data frame can be aggregated by counting rows for each possible value of the `Survived` column:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.groupby('Survived').count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Survived</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>549</td>\n",
        "      <td>549</td>\n",
        "      <td>549</td>\n",
        "      <td>549</td>\n",
        "      <td>424</td>\n",
        "      <td>549</td>\n",
        "      <td>549</td>\n",
        "      <td>549</td>\n",
        "      <td>549</td>\n",
        "      <td>68</td>\n",
        "      <td>549</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>342</td>\n",
        "      <td>342</td>\n",
        "      <td>342</td>\n",
        "      <td>342</td>\n",
        "      <td>290</td>\n",
        "      <td>342</td>\n",
        "      <td>342</td>\n",
        "      <td>342</td>\n",
        "      <td>342</td>\n",
        "      <td>136</td>\n",
        "      <td>340</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "          PassengerId  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\n",
        "Survived                                                                    \n",
        "0                 549     549   549  549  424    549    549     549   549   \n",
        "1                 342     342   342  342  290    342    342     342   342   \n",
        "\n",
        "          Cabin  Embarked  \n",
        "Survived                   \n",
        "0            68       549  \n",
        "1           136       340  "
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(survived_column == 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.61616161616161613"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this the subset of the full passengers list, about 2/3 perished in the event. So if we are to build a predictive model from this data, a baseline model to compare the performance to would be to always predict death. Such a constant model would reach around 62% predictive accuracy (which is higher than predicting at random):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "pandas `Series` instances can be converted to regular 1D numpy arrays by using the `values` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target = survived_column.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "numpy.ndarray"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "dtype('int64')"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([0, 1, 1, 1, 0])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Training a predictive model on numerical features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` estimators all work with homegeneous numerical feature descriptors passed as a numpy array. Therefore passing the raw data frame will not work out of the box.\n",
      "\n",
      "Let us start simple and build a first model that only uses readily available numerical features as input, namely `data.Fare`, `data.Pclass` and `data.Age`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features = data.get(['Fare', 'Pclass', 'Age'])\n",
      "numerical_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>7.2500</td>\n",
        "      <td>3</td>\n",
        "      <td>22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>71.2833</td>\n",
        "      <td>1</td>\n",
        "      <td>38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>7.9250</td>\n",
        "      <td>3</td>\n",
        "      <td>26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>53.1000</td>\n",
        "      <td>1</td>\n",
        "      <td>35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>8.0500</td>\n",
        "      <td>3</td>\n",
        "      <td>35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately some passengers do not have age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numerical_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       714\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's use pandas `fillna` method to input the median age for those passengers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "median_features = numerical_features.dropna().median()\n",
      "median_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "Fare      15.7417\n",
        "Pclass     2.0000\n",
        "Age       28.0000\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features = numerical_features.fillna(median_features)\n",
      "imputed_features.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "Fare      891\n",
        "Pclass    891\n",
        "Age       891\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputed_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>7.2500</td>\n",
        "      <td>3</td>\n",
        "      <td>22</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>71.2833</td>\n",
        "      <td>1</td>\n",
        "      <td>38</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>7.9250</td>\n",
        "      <td>3</td>\n",
        "      <td>26</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>53.1000</td>\n",
        "      <td>1</td>\n",
        "      <td>35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>8.0500</td>\n",
        "      <td>3</td>\n",
        "      <td>35</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "      Fare  Pclass  Age\n",
        "0   7.2500       3   22\n",
        "1  71.2833       1   38\n",
        "2   7.9250       3   26\n",
        "3  53.1000       1   35\n",
        "4   8.0500       3   35"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the data frame is clean, we can convert it into an homogeneous numpy array of floating point values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array = imputed_features.values\n",
      "features_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([[  7.25  ,   3.    ,  22.    ],\n",
        "       [ 71.2833,   1.    ,  38.    ],\n",
        "       [  7.925 ,   3.    ,  26.    ],\n",
        "       ..., \n",
        "       [ 23.45  ,   3.    ,  28.    ],\n",
        "       [ 30.    ,   1.    ,  26.    ],\n",
        "       [  7.75  ,   3.    ,  32.    ]])"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_array.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "dtype('float64')"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take the 80% of the data for training a first model and keep 20% for computing is generalization score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "(712, 3)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "(179, 3)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "(712,)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(179,)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's start with a simple model from sklearn, namely `LogisticRegression`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "logreg.fit(features_train, target_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
        "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
        "          verbose=0)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted = logreg.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "accuracy_score(target_test, target_predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This first model has around 73% accuracy: this is better than our baseline that always predicts death."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model evaluation and interpretation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpreting linear model weights"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `coef_` attribute of a fitted linear model such as `LogisticRegression` holds the weights of each features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = numerical_features.columns\n",
      "feature_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "Index(['Fare', 'Pclass', 'Age'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "array([[ 0.0043996 , -0.80916725, -0.03348064]])"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(len(feature_names))\n",
      "plt.bar(x, logreg.coef_.ravel())\n",
      "_ = plt.xticks(x + 0.5, feature_names, rotation=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEJCAYAAABv6GdPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZNwlqUHGXZIaZNwlqUH/B20Xy1kH0Cg8AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1095153c8>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, survival is slightly positively linked with Fare (the higher the fare, the higher the likelyhood the model will predict survival) while passenger from first class and lower ages are predicted to survive more often than older people from the 3rd class.\n",
      "\n",
      "First-class cabins were closer to the lifeboats and children and women reportedly had the priority. Our model seems to capture that historical data. We will see later if the sex of the passenger can be used as an informative predictor to increase the predictive accuracy of the model."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Alternative evaluation metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is possible to see the details of the false positive and false negative errors by computing the confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "cm = confusion_matrix(target_test, target_predicted)\n",
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The true labeling are seen as the rows and the predicted labels are the columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_confusion(cm):\n",
      "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.binary)\n",
      "    plt.title('Confusion matrix')\n",
      "    plt.set_cmap('Blues')\n",
      "    plt.colorbar()\n",
      "\n",
      "    target_names = ['not survived', 'survived']\n",
      "\n",
      "    tick_marks = np.arange(len(target_names))\n",
      "    plt.xticks(tick_marks, target_names, rotation=60)\n",
      "    plt.yticks(tick_marks, target_names)\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    # Convenience function to adjust plot parameters for a clear layout.\n",
      "    plt.tight_layout()\n",
      "    \n",
      "plot_confusion(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAEaCAYAAACB7ptqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1096c06a0>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cm)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[98 12]\n",
        " [36 33]]\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can normalize the number of prediction by dividing by the total number of true \"survived\" and \"not survived\" to compute false and true positive rates for survival (in the second column of the confusion matrix)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(cm.astype(np.float64) / cm.sum(axis=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.89090909  0.17391304]\n",
        " [ 0.32727273  0.47826087]]\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can therefore observe that the fact that the target classes are not balanced in the dataset makes the accuracy score not very informative.\n",
      "\n",
      "scikit-learn provides alternative classification metrics to evaluate models performance on imbalanced data such as precision, recall and f1 score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print(classification_report(target_test, target_predicted,\n",
      "                            target_names=['not survived', 'survived']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "not survived       0.73      0.89      0.80       110\n",
        "    survived       0.73      0.48      0.58        69\n",
        "\n",
        " avg / total       0.73      0.73      0.72       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way to quantify the quality of a binary classifier on imbalanced data is to compute the precision, recall and f1-score of a model (at the default fixed decision threshold of 0.5)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Logistic Regression is a probabilistic models: instead of just predicting a binary outcome (survived or not) given the input features it can also estimates the posterior probability of the outcome given the input features using the `predict_proba` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_predicted_proba = logreg.predict_proba(features_test)\n",
      "target_predicted_proba[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([[ 0.75263264,  0.24736736],\n",
        "       [ 0.75824771,  0.24175229],\n",
        "       [ 0.58542437,  0.41457563],\n",
        "       [ 0.25224882,  0.74775118],\n",
        "       [ 0.75817844,  0.24182156]])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default the decision threshold is 0.5: if we vary the decision threshold from 0 to 1 we could generate a family of binary classifier models that address all the possible trade offs between false positive and false negative prediction errors.\n",
      "\n",
      "We can summarize the performance of a binary classifier for all the possible thresholds by plotting the ROC curve and quantifying the Area under the ROC curve:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "from sklearn.metrics import auc\n",
      "\n",
      "def plot_roc_curve(target_test, target_predicted_proba):\n",
      "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
      "    \n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    # Plot ROC curve\n",
      "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
      "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.0])\n",
      "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
      "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
      "    plt.title('Receiver Operating Characteristic')\n",
      "    plt.legend(loc=\"lower right\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(target_test, target_predicted_proba)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109534b00>"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here the area under ROC curve is 0.756 which is very similar to the accuracy (0.732). However the ROC-AUC score of a random model is expected to 0.5 on average while the accuracy score of a random model depends on the class imbalance of the data. ROC-AUC can be seen as a way to callibrate the predictive accuracy of a model against class imbalance."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We previously decided to randomly split the data to evaluate the model on 20% of held-out data. However the location randomness of the split might have a significant impact in the estimated accuracy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=0)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.73184357541899436"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=1)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "0.67039106145251393"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_train, features_test, target_train, target_test = train_test_split(\n",
      "    features_array, target, test_size=0.20, random_state=2)\n",
      "\n",
      "logreg.fit(features_train, target_train).score(features_test, target_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "0.66480446927374304"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So instead of using a single train / test split, we can use a group of them and compute the min, max and mean scores as an estimation of the real test score while not underestimating the variability:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(logreg, features_array, target, cv=5)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "array([ 0.63128492,  0.68715084,  0.70224719,  0.73033708,  0.71751412])"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "(0.63128491620111726, 0.69370682962933028, 0.7303370786516854)"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`cross_val_score` reports accuracy by default be it can also be used to report other performance metrics such as ROC-AUC or f1-score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(logreg, features_array, target, cv=5,\n",
      "                         scoring='roc_auc')\n",
      "scores.min(), scores.mean(), scores.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "(0.61093544137022393, 0.72123181651091728, 0.78776737967914434)"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Compute cross-validated scores for other classification metrics ('precision', 'recall', 'f1', 'accuracy'...).\n",
      "\n",
      "- Change the number of cross-validation folds between 3 and 10: what is the impact on the mean score? on the processing time?\n",
      "\n",
      "Hints:\n",
      "\n",
      "The list of classification metrics is available in the online documentation:\n",
      "\n",
      "  http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\n",
      "  \n",
      "You can use the `%%time` cell magic on the first line of an IPython cell to measure the time of the execution of the cell. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "More feature engineering and richer models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us now try to build richer models by including more features as potential predictors for our model.\n",
      "\n",
      "Categorical variables such as `data.Embarked` or `data.Sex` can be converted as boolean indicators features also known as dummy variables or one-hot-encoded features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.get_dummies(data.Sex, prefix='Sex').head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Sex_male</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "   Sex_female  Sex_male\n",
        "0           0         1\n",
        "1           1         0\n",
        "2           1         0\n",
        "3           1         0\n",
        "4           0         1"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.get_dummies(data.Embarked, prefix='Embarked').head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "   Embarked_C  Embarked_Q  Embarked_S\n",
        "0           0           0           1\n",
        "1           1           0           0\n",
        "2           0           0           1\n",
        "3           0           0           1\n",
        "4           0           0           1"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can combine those new numerical features with the previous features using `pandas.concat` along `axis=1`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features = pd.concat([data.get(['Fare', 'Pclass', 'Age']),\n",
      "                           pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                           pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
      "                          axis=1)\n",
      "rich_features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Sex_male</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>7.2500</td>\n",
        "      <td>3</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>71.2833</td>\n",
        "      <td>1</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>7.9250</td>\n",
        "      <td>3</td>\n",
        "      <td>26</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>53.1000</td>\n",
        "      <td>1</td>\n",
        "      <td>35</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>8.0500</td>\n",
        "      <td>3</td>\n",
        "      <td>35</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
        "0   7.2500       3   22           0         1           0           0   \n",
        "1  71.2833       1   38           1         0           1           0   \n",
        "2   7.9250       3   26           1         0           0           0   \n",
        "3  53.1000       1   35           1         0           0           0   \n",
        "4   8.0500       3   35           0         1           0           0   \n",
        "\n",
        "   Embarked_S  \n",
        "0           1  \n",
        "1           0  \n",
        "2           1  \n",
        "3           1  \n",
        "4           1  "
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By construction the new `Sex_male` feature is redundant with `Sex_female`. Let us drop it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features_no_male = rich_features.drop('Sex_male', 1)\n",
      "rich_features_no_male.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>7.2500</td>\n",
        "      <td>3</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>71.2833</td>\n",
        "      <td>1</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>7.9250</td>\n",
        "      <td>3</td>\n",
        "      <td>26</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>53.1000</td>\n",
        "      <td>1</td>\n",
        "      <td>35</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>8.0500</td>\n",
        "      <td>3</td>\n",
        "      <td>35</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S\n",
        "0   7.2500       3   22           0           0           0           1\n",
        "1  71.2833       1   38           1           1           0           0\n",
        "2   7.9250       3   26           1           0           0           1\n",
        "3  53.1000       1   35           1           0           0           1\n",
        "4   8.0500       3   35           0           0           0           1"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us not forget to imput the median age for passengers without age information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rich_features_final = rich_features_no_male.fillna(rich_features_no_male.dropna().median())\n",
      "rich_features_final.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>7.2500</td>\n",
        "      <td>3</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>71.2833</td>\n",
        "      <td>1</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>7.9250</td>\n",
        "      <td>3</td>\n",
        "      <td>26</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>53.1000</td>\n",
        "      <td>1</td>\n",
        "      <td>35</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>8.0500</td>\n",
        "      <td>3</td>\n",
        "      <td>35</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S\n",
        "0   7.2500       3   22           0           0           0           1\n",
        "1  71.2833       1   38           1           1           0           0\n",
        "2   7.9250       3   26           1           0           0           1\n",
        "3  53.1000       1   35           1           0           0           1\n",
        "4   8.0500       3   35           0           0           0           1"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can finally cross-validate a logistic regression model on this new data an observe that the mean score has significantly increased:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "logreg = LogisticRegression(C=1)\n",
      "scores = cross_val_score(logreg, rich_features_final, target, cv=5, scoring='accuracy')\n",
      "print(\"Logistic Regression CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic Regression CV scores:\n",
        "min: 0.770, mean: 0.786, max: 0.810\n",
        "CPU times: user 23.5 ms, sys: 1.4 ms, total: 24.9 ms\n",
        "Wall time: 24 ms\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- change the value of the parameter `C`. Does it have an impact on the score?\n",
      "\n",
      "- fit a new instance of the logistic regression model on the full dataset.\n",
      "\n",
      "- plot the weights for the features of this newly fitted logistic regression model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04A_plot_logistic_regression_weights.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training Non-linear models: ensembles of randomized trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`sklearn` also implement non linear models that are known to perform very well for data-science projects where datasets have not too many features (e.g. less than 5000).\n",
      "\n",
      "In particular let us have a look at Random Forests and Gradient Boosted Trees:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "scores = cross_val_score(rf, rich_features_final, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "print(\"Random Forest CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest CV scores:\n",
        "min: 0.765, mean: 0.801, max: 0.826\n",
        "CPU times: user 90.8 ms, sys: 30.4 ms, total: 121 ms\n",
        "Wall time: 726 ms\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                subsample=.8, max_features=.5)\n",
      "scores = cross_val_score(gb, rich_features_final, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy')\n",
      "print(\"Gradient Boosted Trees CV scores:\")\n",
      "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
      "    scores.min(), scores.mean(), scores.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Gradient Boosted Trees CV scores:\n",
        "min: 0.803, mean: 0.825, max: 0.847\n",
        "CPU times: user 70 ms, sys: 23.4 ms, total: 93.5 ms\n",
        "Wall time: 476 ms\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both models seem to do slightly better than the logistic regression model on this data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise**:\n",
      "\n",
      "- Change the value of the learning_rate and other `GradientBoostingClassifier` parameter, can you get a better mean score?\n",
      "\n",
      "- Would treating the `PClass` variable as categorical improve the models performance?\n",
      "\n",
      "- Find out which predictor variables (features) are the most informative for those models.\n",
      "\n",
      "Hints:\n",
      "\n",
      "Fitted ensembles of trees have `feature_importances_` attribute that can be used similarly to the `coef_` attribute of linear models."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04B_more_categorical_variables.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load solutions/04C_feature_importance.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automated parameter tuning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of changing the value of the learning rate manually and re-running the cross-validation, we can find the best values for the parameters automatically (assuming we are ready to wait):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "gb = GradientBoostingClassifier(n_estimators=100, subsample=.8)\n",
      "\n",
      "params = {\n",
      "    'learning_rate': [0.05, 0.1, 0.5],\n",
      "    'max_features': [0.5, 1],\n",
      "    'max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(gb, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(rich_features_final, target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 685 ms, sys: 40.8 ms, total: 726 ms\n",
        "Wall time: 6.69 s\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us sort the models by mean validation score:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(gs.grid_scores_, key=lambda x: x.mean_validation_score, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "[mean: 0.87467, std: 0.02393, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 4},\n",
        " mean: 0.87269, std: 0.02820, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 4},\n",
        " mean: 0.87244, std: 0.02383, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 3},\n",
        " mean: 0.87205, std: 0.02628, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 4},\n",
        " mean: 0.87003, std: 0.02644, params: {'max_features': 0.5, 'learning_rate': 0.1, 'max_depth': 5},\n",
        " mean: 0.86876, std: 0.02444, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 5},\n",
        " mean: 0.86874, std: 0.02383, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 3},\n",
        " mean: 0.86872, std: 0.02452, params: {'max_features': 0.5, 'learning_rate': 0.05, 'max_depth': 5},\n",
        " mean: 0.86870, std: 0.02388, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 4},\n",
        " mean: 0.86499, std: 0.01880, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 3},\n",
        " mean: 0.86463, std: 0.02718, params: {'max_features': 1, 'learning_rate': 0.1, 'max_depth': 5},\n",
        " mean: 0.86387, std: 0.03035, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 3},\n",
        " mean: 0.86301, std: 0.02485, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 3},\n",
        " mean: 0.85959, std: 0.02968, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 4},\n",
        " mean: 0.85880, std: 0.02125, params: {'max_features': 1, 'learning_rate': 0.05, 'max_depth': 3},\n",
        " mean: 0.85606, std: 0.02290, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 4},\n",
        " mean: 0.84272, std: 0.02670, params: {'max_features': 1, 'learning_rate': 0.5, 'max_depth': 5},\n",
        " mean: 0.83861, std: 0.01556, params: {'max_features': 0.5, 'learning_rate': 0.5, 'max_depth': 5}]"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "0.87467064281685669"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "{'learning_rate': 0.1, 'max_depth': 4, 'max_features': 0.5}"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We should note that the mean scores are very close to one another and almost always within one standard deviation of one another. This means that all those parameters are quite reasonable. The only parameter of importance seems to be the `learning_rate`: 0.5 seems to be a bit too high."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Avoiding data snooping with pipelines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When doing imputation in pandas, prior to computing the train test split we use data from the test to improve the accuracy of the median value that we impute on the training set. This is actually cheating. To avoid this we should compute the median of the features on the training fold and use that median value to do the imputation both on the training and validation fold for a given CV split.\n",
      "\n",
      "To do this we can prepare the features as previously but without the imputation: we just replace missing values by the -1 marker value:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = pd.concat([data.get(['Fare', 'Age']),\n",
      "                      pd.get_dummies(data.Sex, prefix='Sex'),\n",
      "                      pd.get_dummies(data.Pclass, prefix='Pclass'),\n",
      "                      pd.get_dummies(data.Embarked, prefix='Embarked')],\n",
      "                     axis=1)\n",
      "features = features.drop('Sex_male', 1)\n",
      "\n",
      "# Because of the following bug we cannot use NaN as the missing\n",
      "# value marker, use a negative value as marker instead:\n",
      "# https://github.com/scikit-learn/scikit-learn/issues/3044\n",
      "features = features.fillna(-1)\n",
      "features.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Fare</th>\n",
        "      <th>Age</th>\n",
        "      <th>Sex_female</th>\n",
        "      <th>Pclass_1</th>\n",
        "      <th>Pclass_2</th>\n",
        "      <th>Pclass_3</th>\n",
        "      <th>Embarked_C</th>\n",
        "      <th>Embarked_Q</th>\n",
        "      <th>Embarked_S</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>7.2500</td>\n",
        "      <td>22</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>71.2833</td>\n",
        "      <td>38</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>7.9250</td>\n",
        "      <td>26</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>53.1000</td>\n",
        "      <td>35</td>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>8.0500</td>\n",
        "      <td>35</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "      <td>0</td>\n",
        "      <td>0</td>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "      Fare  Age  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  \\\n",
        "0   7.2500   22           0         0         0         1           0   \n",
        "1  71.2833   38           1         1         0         0           1   \n",
        "2   7.9250   26           1         0         0         1           0   \n",
        "3  53.1000   35           1         1         0         0           0   \n",
        "4   8.0500   35           0         0         0         1           0   \n",
        "\n",
        "   Embarked_Q  Embarked_S  \n",
        "0           0           1  \n",
        "1           0           0  \n",
        "2           0           1  \n",
        "3           0           1  \n",
        "4           0           1  "
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use the `Imputer` transformer of scikit-learn to find the median value on the training set and apply it on missing values of both the training set and the test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(features.values, target, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import Imputer\n",
      "\n",
      "imputer = Imputer(strategy='median', missing_values=-1)\n",
      "\n",
      "imputer.fit(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 69,
       "text": [
        "Imputer(axis=0, copy=True, missing_values=-1, strategy='median', verbose=0)"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The median age computed on the training set is stored in the `statistics_` attribute."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imputer.statistics_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "array([ 14.5,  29. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   1. ])"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Imputation can now happen by calling  the transform method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_imputed = imputer.transform(X_train)\n",
      "X_test_imputed = imputer.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_train == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 72,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_train_imputed == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_test == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.any(X_test_imputed == -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use a pipeline that wraps an imputer transformer and the classifier itself:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "imputer = Imputer(strategy='median', missing_values=-1)\n",
      "\n",
      "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
      "                                        subsample=.8, max_features=.5)\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('imp', imputer),\n",
      "    ('clf', classifier),\n",
      "])\n",
      "\n",
      "scores = cross_val_score(pipeline, features.values, target, cv=5, n_jobs=4,\n",
      "                         scoring='accuracy', )\n",
      "print(scores.min(), scores.mean(), scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.804469273743 0.823838396304 0.847457627119\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The mean cross-validation is slightly lower than we used the imputation on the whole data as we did earlier although not by much. This means that in this case the data-snooping was not really helping the model cheat by much.\n",
      "\n",
      "Let us re-run the grid search, this time on the pipeline. Note that thanks to the pipeline structure we can optimize the interaction of the imputation method with the parameters of the downstream classifier without cheating:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "params = {\n",
      "    'imp__strategy': ['mean', 'median'],\n",
      "    'clf__max_features': [0.5, 1],\n",
      "    'clf__max_depth': [3, 4, 5],\n",
      "}\n",
      "gs = GridSearchCV(pipeline, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
      "gs.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 438 ms, sys: 35.3 ms, total: 474 ms\n",
        "Wall time: 5.19 s\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(gs.grid_scores_, key=lambda x: x.mean_validation_score, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "[mean: 0.87247, std: 0.02822, params: {'clf__max_depth': 3, 'clf__max_features': 0.5, 'imp__strategy': 'median'},\n",
        " mean: 0.86955, std: 0.02398, params: {'clf__max_depth': 4, 'clf__max_features': 0.5, 'imp__strategy': 'median'},\n",
        " mean: 0.86656, std: 0.02690, params: {'clf__max_depth': 3, 'clf__max_features': 0.5, 'imp__strategy': 'mean'},\n",
        " mean: 0.86653, std: 0.02757, params: {'clf__max_depth': 4, 'clf__max_features': 1, 'imp__strategy': 'median'},\n",
        " mean: 0.86647, std: 0.03362, params: {'clf__max_depth': 4, 'clf__max_features': 0.5, 'imp__strategy': 'mean'},\n",
        " mean: 0.86485, std: 0.02392, params: {'clf__max_depth': 5, 'clf__max_features': 0.5, 'imp__strategy': 'median'},\n",
        " mean: 0.86228, std: 0.02912, params: {'clf__max_depth': 3, 'clf__max_features': 1, 'imp__strategy': 'mean'},\n",
        " mean: 0.86186, std: 0.02045, params: {'clf__max_depth': 4, 'clf__max_features': 1, 'imp__strategy': 'mean'},\n",
        " mean: 0.86033, std: 0.02211, params: {'clf__max_depth': 5, 'clf__max_features': 0.5, 'imp__strategy': 'mean'},\n",
        " mean: 0.85683, std: 0.02289, params: {'clf__max_depth': 5, 'clf__max_features': 1, 'imp__strategy': 'median'},\n",
        " mean: 0.85636, std: 0.02372, params: {'clf__max_depth': 3, 'clf__max_features': 1, 'imp__strategy': 'median'},\n",
        " mean: 0.85595, std: 0.03049, params: {'clf__max_depth': 5, 'clf__max_features': 1, 'imp__strategy': 'mean'}]"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "0.87246832623242643"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_roc_curve(y_test, gs.predict_proba(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8XPP9x/HXOxFiSWRRFYl9CWpLEEpVLCX2/iiqWqUL\n1aK/FlXaElX8lFrb2pdSS621NihCagsSiS32iAhKLEHs+fz++H4nOXcyM/fMvXPmzPJ5Ph73cefM\nOXPO55x753zPd5eZ4ZxzzhX0yDsA55xzjcUTBueccx14wuCcc64DTxicc8514AmDc865DjxhcM45\n14EnDK5Tkp6Q9PW842gUko6QdF5Ox75Y0rF5HLvWJO0l6bYuftb/JzPkCUOTkTRV0mxJ70t6XdKl\nkvpmeUwzW9PM7s3yGAWSFpJ0gqSX43k+K+nQehy7TDwjJb2SfM/MTjCzH2d0PEk6WNLjkj6Q9Iqk\nqyStWTh8/MmVpNGSLu3OPszsMjPbJsWx5ksM6/k/2Y48YWg+BuxgZn2AdYC1gN/mG1L1JC1QZtXV\nwObAtsBiwPeA/SSdnkEMkqRa77ebTgcOBg4C+gOrAv8Etqv1gST1rPU+m+HYLgUz858m+gFeArZI\nLP8RuCWxvBFwP/AO8BiwWWLdAOAi4FXgbeD6xLod4vbvAPcBayXWTQW2AJYGZgP9E+uGAW8CPePy\nD4Cn4v7HAMsmtp0D/BR4DnihxLltCXwEDC56fwTwObBiXB4LnAA8BLxHuHH2T3kNxgJ/iOc4G1gJ\n2DfGPAt4AdgvbrtojOcL4P24fhAwGrg0brN8PK+9gZfjtTgycbyFgb/F6/EU8CvglTJ/21Xiea5f\n4e9/EfBn4OYYz4OF6xLXnw5Mi9flEeBriXWjgWuAS+P6HwAbAA/EazUDOBPolfjMV4A7gJnA68AR\nwDbAJ8Cn8bpMjNsuDlwQ9zMdOBboEdftE6/5KcBbcd0+wLi4XsCpwBsxtsnx2PvF43wSj3VD4n9y\ny/i6J3Ak8Hy8Jo8AQ/L+rjbzT+4B+E+Vf7CQMBS+EEPiF+iouDw4fulGxeWt4vLAuHwLcEX8Ai8A\nbBrfHxa/kBvEL+je8Ti9EsfcIr6+E/hRIp6TgL/G1zsTbvpDCbnR3wD3JbadA9wG9AMWKnFu/wfc\nXea8pwI/jq/HxhvPGsAihZtdymswNu5r9RjjAoSn8RXi+q8DHwLD4vJmFN3IgaOZP2E4B1gIWBv4\nGBiaPKd4zQfHv9e0Muf4E+ClTv7+F8fzWT/eEP8OXJFYvxchp9ED+CXwGrBgXDeacJPdKS73BoYT\nEt4ewHKExOvncX2f+PlfAAsScnAjEtfgkqLYrgfOIiSGXyIk3IVEdh/gM+Bn8Vi96ZgwbEO4ofeN\ny0OBpeLri4Dfl/geFP4nD4vXdZW4vBYwIO/vajP/eFFS8xHwT0mzCE+GLxCegAG+C9xqZmMAzOzf\nhC/b9pIGAaOAn5jZe2b2uZmNi5/bDzjHzB624BLCE9pGJY5/ObAnhKIYYI/4HoQb2wlm9oyZzSE8\n1a8raZnE508ws3fN7JMS+16C8FRaymtxPYTitEvM7Ckzmw38DthdUo9K1yDx2YvN7GkzmxOvw61m\n9lLc/l7gdmDTuH2poqZS7x1jZp+Y2WRgEqGYD2A34Ph4zV8lPNGXK74aWOH8Cwy4zsweMbMvgMuA\ndeeuDOX278RzO4WQWA1NfP5+M7sxbvuxmU0ws/Fx+5eBcwmJIYRc5AwzO9XMPjWzD8xsfOIazD0P\nSV8mFP/9wsw+MrM3gdOAbyeOPcPM/hKP9XHReX1GSIhWl9Qj/g8lr0WlIr8fAb8xs+fieT1uZm9X\n2N51whOG5mPAzmbWFxhJKOJZP65bDthN0juFH2ATYClgGeBtM3uvxD6XAw4p+twQQtFRseuAr0pa\nivB0PcfM/pPYz+mJfcyM7w9OfL5DRW6RNwlFNaUsTXhSLrWfaUAvQsJR6RqUjEHStpIelDQzbr8d\n4SZdjeRNbDbh6boQd/J40yvsYyblzz/pjcTrjxLHQtKhkp6S9G48l8WZl6DOd3xJq0q6WdJrkt4D\njmPeuS8DvJgiHgjXvRfwWuK6n03IORSU/dub2V2EIrK/AG9IOkdSn5THHkJ4QHI14glDE4tPt2cC\nJ8a3phGKOPonfvqY2R8JX8oBkhYvsatpwHFFn1vMzP5R4pjvEJ6o9wC+QyiaSu5nv6L9LGpmDyZ3\nUeGU/g1sKGlI8k1JGxK+/Hcl3l626PVnhISl0jWYLwZJCwHXEupqljSz/sCtzHtCLRVvNa2CXiPc\nYAuWKbchoZhuiKT1qtj/XJI2JRSr7GZm/eK5vEfHp+3i2M8iFB+tbGaLE4r/CveFacCKZQ43p2j5\nFUIuc2Diui9uZmtVOHYHZnamma1PKCJcNZ5Lp5+Lx165k21cFTxhaH6nASPizfPvwI6StpbUU1Lv\n2NxysJm9BvwL+KukfpJ6JdqBnwf8RNKI2FBnUUnbS1qszDEvB74P7Mq8YiQIT4hHSloDQNLiknZL\neyJmdifh5nitpDXiOWxEqCz9q5kVngoFfFfS6pIWAX4PXG1mVukaJA6VvFEuGH/eAuZI2hbYOrH+\nDWBgUZPgaloyXQUcEa/5YOBAytzoYlHIX4ErJG0macEY/7clHZ7i2H0Ilddvxc8eBXTWlHkxQqXu\nbEmrAQck1t0CDJL089iMuI+kEXHdG8DyhVZd8f/rduCUuF0PSSspZV8DSetL2lBSL0KO62NCpX/h\nWOUSKIDzgWMlrRz/f9eWNCDNcV1pnjA0OTN7i9Dq5XAzm06oAD4S+C/hie8Q5v2dv0d4sp5C+LId\nHPfxKPBjQlb+bUIF8t6Uf1K7kfCE9pqZPZ6I5Z+E3MuVsVjicUKl4txNUpzSroTK2jGEG9alwPlm\ndlDRfi4lVMS+RrixF86l3DUo+dRsZu/Hz14Vz31P4IbE+imEXNGLkt6OdTXFfQkqndfvCcU3LxFu\nnFcTKoBLMrODmVek8g6hpc3OhGteOFbx8QrLY+LPs4QK9o8I55/crvizhxJyfrMI9QtXFraJ1+Yb\nwI6E6/wsofiSeB4AMyU9El/vTfhbFFqlXc28IrxycRfe6xuP/3aM/S1CwwYILZ3WiEVU1zG/Uwh/\nv9sJOaTzCJXbrosUHrIy2rl0IaHS779FWcrkNmcQKq1mA/uY2cTMAnItQdLdhOKiC/OOpVqSDgB2\nN7PN847FuXKyzjFcRGgJU5Kk7Qhlm6sQWsaclXE8rnU0Wse0kiQtJWmTWLQylNCE9Pq843KukkwT\nhtgc8p0Km+xEKAbBzB4C+sVmb851JvdhIVJakFD3MotQf/JPQj2Ccw2r3LAE9TKY+ZvyDaFjczzn\nOmimYhgzm0bocOVc02iEyufiIoFmeRJ0zrmWlHeO4VU6tuseEt/rQJInFs451wVmVnV9XN4Jw42E\ndt1Xxvbq75pZyWKkrpxcK5I02sxG5x1HI/BrMY9fi3na9VpIGga9r4CNB8NdQ81sRlcfqjNNGCRd\nQRh3ZQmFMe2PJnSbx8zOMbNbJW0n6XnCwGX7ZhmPc861Ikm/AI6AwybC6GfMeszozv4yTRjMbM8U\n2xyYZQzOOdcGHoZHz4XhOxPGMOuWvIuSXPXG5h1AAxmbdwANZGzeAXRGYmlCj/SMG71csrTUbk2C\nbTFCgrCJWcUuAqlk2vO5ViSZ1zE419wktiGM7XVm3rG0qFvNmJp8o6v3Ts8xOOfqaZpZuz3N14ak\nBQmj375rZqdmeaxG6MfgnGsREvtJvF3qhzDT3od5x9iMQosjHgbWA+YbDr/WPMfgnKulwYTRTU8s\ns/6DOsbS9BK5hAMII+FeanUo//eEwbk2EiuAv5LhIVYCnjPDp9asjdMIE1Gta2bdaoJaDU8YnGsv\nvwG2pPIUq911eeebuJQOBz6oRy4hyRMG59pLD+B0Mx/ivhnEyZLqzhMG5xqYRE/gd1SeK7oamwCT\na7QvVyOxLqGPmc3MOxbwfgzONSwJEeZyWJUwl3Wt3GzmQ9s3itji6GLgGjM7tsb79n4MzrWYo4H1\ngc3NmJV3MK62SrU4yjeieTxhcG1HYigwnsb//58OfN0ThdaTyCW8Qp1bHKXR6F8M57LQD3iOMPJv\nI/vEjM/zDsJlYnPgT9SpX0K1PGFwDUdiYWALsuuZPxT4wsx74bp8mNkpecdQiScMrhFtCVxAKO7J\nyo0Z7tu5puYJg2tEAsabsWPegTjXHbEuoZ+Z3Z13LNXwhMHVhMQOQKcTM6U0BHivRvtyru6KWhz9\nNOdwquYJg6uVrYEvgNtqtL/Ha7Qf5+qq0VscpeEJg6ulR8y4LO8gnMuLpAOBo6jjSKhZ8IShhUg8\nAqyb0+F7At/P6djONYoHaNJcQpInDK1lScLwCdPyOLi3uXftzswezTuGWvCEoclJLAKMIrT5XwT4\n3G/Qzrnu8ISh+W0G/BX4DzAGeCvfcJxrbYkWR3PM7Ji848mCJwzNT8AEM76VdyDOtbqiFkf75RtN\ndrIacsA551qGpAUlHUNojv0nYMdmr2CuxHMMzjnXueOA1WmBFkdppE4YJPUGzMw+yTAe14k4o1dy\n4o2eecXiXBs5Cvi4WfslVKtswiCpB/BNwjAHGxOKnSTpC0Jb3cuAf7bLhWoEEgOBGcyfGHinMucy\nZGYf5R1DPZWd2lPSvcA4wiiUjxVyCpIWAoYBOwFfM7OvZx6kT+0JgMQQ4EEzhuQdi3OtKLY4GmBm\nr+cdSy109d5ZKWFYqLNiozTb1EI7JAwS6wBrdrLZQOBXnjA4V3uJFke3mNmROYdTEzWf8zmRQzgF\nuMDMniy3jeue2EntDuBOYE4nm1+QfUTOtY9Gnns5L2kqn58GzpXUC7gQuMLMfEjk2vo+cL9ZzYat\nds6l0AojoWahbFHSfBtKqwH7AN8h9LI9r16TT7RyUVJsZTQF2NeM/+Qdj3PtRNKPgE9p4pFQK+nq\nvTNVBzdJPYHVCO143wQmAb+U9I9qD+jmsxMwE7gv70Ccazdmdr6ZXdKKiUJ3dJpjkHQqsCNwF3C+\nmY1PrHvGzIZmG2LL5xjuA04145q8Y3HOtZaat0pK7Hhf4Coz+7DEun5m9m61B61WqyYMEssDDwFL\nm/FFzuE417JiXcJgM7s571jqKcuipO8VJwqS7gToLFGQNErSFEnPSTq8xPolJI2R9JikJyTtU03w\nLWAh4F1PFJzLRtEYR4vmHU+zqNTzeWHC+P5LSBqQWNUXGNzZjmO9xJ+BrYBXgYcl3WhmTyc2OxCY\naGZHSFoCeEbS383M5xNwznWLtzjqukrNVfcHfg4sDSRnJXqfcMPvzAjgeTObCiDpSmBnQvPXgteA\ntePrvsBMTxScc90laT/gDzT53Mt5qdTB7TTgNEkHmdmZXdj3YEJKXTAd2LBom/OAuyTNAPoAu3fh\nOM45V+w/eC6hyyoVJW1hZncBMyTtUrzezK7rZN9pUugjCeMwjZS0EnCHpHXM7P0S8YxOLI41s7Ep\n9u+ca0Nm9lTeMeRB0khgZHf3U6koaTNCE9UdKX2T7yxheBVYJrG8DCHXkLQxYZxzzOwFSS8BQ4FH\nindmZqM7OZ5zrg0pNr3JO45GEB+YxxaWJR3dlf1UKkoq7PBHXSz3fwRYRdLyhKGi94D5hnyYQqic\nvk/SlwmJwotdOJZzrs0kxjjqA/wy53BaSprmqi9KOlfSlpJSt4eNicmBhGZiTwH/MLOnJe0vaf+4\n2fHA+pImAf8GfmVmb1d5Ds65NhNbHD0MrAecnHM4LSdNB7dFgR2AbwPDgZsIN/lx2Yc3N4ZW7eA2\nFLjRjMx7jzvXCkqNhOrFSOXVfNjtgti57R/APyT1B84glGH5lJJdJLEGoYLoyzmH4lyzOZKQS/AW\nRxlKNedzrOneAxhFyL55s9Lu+TGhn8ck0vUJcc4FxwOfeS4hW50mDJKmAo8Rcg2HmdkHWQfVJq4x\n49S8g3CumZjZp3nH0A7S5BjWNrNZmUfSoiQ2Av5Y9PZKwIk5hONcU4h1CUuZ2bS8Y2lHlTq4HW5m\nJwLHlWiMZGZ2cKaRtY7VgQ+BE4ren5hDLM41vMQYR3fizVBzUSnHUOg5+CgdO7iJdL2a25LEknS8\nrv2B1824N6eQnGsKPvdy46jUwe2m+HK2mV2VXCfJK59LiK2NJhFmuUs6K4dwnGsaPhJqY0nTj2Gi\nmQ3r7L0sNUs/BonhwPlmDM87FueaSXzY7I33S6ipmvdjkLQtsB0wWNIZhCIkCN3PP+tSlM45V0Jx\nqYTLV6U6hhmE+oWd4+9CwjAL+EXGcTnnnMtJpTqGScAkSZeZmecQnHPdFusShprZlXnH4sqrVJR0\ntZntBkwo01x17RIfaykSKwCXkX74j0WB2dlF5FxzKmpx9L85h+M6Uako6efx9471CKRBDSHc7Per\n4jOvZRSLc03JWxw1n0pFSYU/3pvAx2b2haShhDkT/lWP4OpBohchAShlaWCWGQ/VMSTnWoakfQg9\n/30k1CaSprnqBOBrhI5a9xEG0fvUzPbKPry5MWTWXFXif4FjgHLzQNxmxk+yOLZzrU7SioQHS88l\n5CCzYbcJicdsST8E/mpmf4wT67SKhYCzzTg870CcazVm5jMyNqE0M7gh6avAXsAt1XzOOdc+qpnh\n0TW2NDf4/wWOAK43syclrQTcnW1YzrlmIWlBSccA5+Udi6uNNDO43QPck1h+AfCRVZ1zxS2Oqmm9\n5xpYmol6hhJaFCyf2N7MbIsM46opiaOAXcqs/jJwQR3Dca7p+dzLrS1N5fPVhNFBzwe+yDaczKwH\n/I3yRWAv1DEW51rBQfjcyy0rTXPVR81svTrFUy6GbjVXlbgBuNCMG2oYlnNtS9ICwBeeS2hsXb13\npql8vknSzyQNkjSg8NOFGJ1zLcLMPvdEoXWlKUrahzBj26FF769Q82iccw0l1iUsZ2bP5R2Lq580\nrZKWr0MczrkGk2hxdB/w03yjcfXUaVGSpEUl/U7SeXF5FUk7ZB+acy4PsV/C74HbgJOBn+Uckquz\nNHUMFwGfAhvH5RnAcZlF5JzLTcwlPAIMI7Q48maobShNwrCSmZ1ISBwwsw+zDck5l6OlgJOAnbwZ\navtKU/n8iaSFCwtxSIxPsgvJOZcXM2uZIfVd16VJGEYDY4Ahki4HNiG0VHLOOdeC0rRKuj3OybBR\nfOtgM3sr27Ccc1mSNBwYbmbn5x2Lazxl6xgkLS+pH0BMCGYDWwN7x7bNzrkmk2hxNAb4KO94XGOq\nVPl8FbAIgKR1CWMmvQysC/w1+9C6R2IBiaMlTgDWyDse5/IWcwnJFkeX5RySa1Blx0qSNNnM1o6v\nTwbmmNmvJPUAJpnZWnULsgvjfUgMAp4FjgfmEMZKejOL+JxrdJL2Ak4FDgH+7k1Q20MWU3smd7Yl\nYbIezGxOE03U9IEZJ+QdhHMN4G58JFSXUqWipLslXS3pDKAfcBeApKVJ2VxV0ihJUyQ9J6nknMqS\nRkqaKOkJSWOrjN85l4KZzfBEwaVVqSipB7AHocPLVWb2anx/GLCkmd1WccdST+AZYCvgVeBhYE8z\nezqxTT/COCzbmNl0SUuUavHUjaKkCWYMquZzzjU7ST3MbE7ecbj8ZVGUZGZ2RYk3JyYOqgpllSOA\n581satz2SmBn4OnENt8BrjWz6XHf3gzWuS6KrQV/C6wKfDvncFwTq1SUNFbSYZJWLV4haWgsGrqn\nxOcKBhPmgS2YHt9LWgUYIOluSY9I+l7awJ1z8yRaHA0HfplzOK7JVcoxbA3sBfxF0prA+4QK6cWA\nJ4DLCMVE5aRp9dCL8I+8JaFp7AOSHvSx351Lx+dedlkomzCY2SfAhcCFsb5gibjqLTNLM/fzq8Ay\nieVlCLmGpFfi/j4CPpJ0L7AOMF/CIGl0YnGsmY1NEYNzre4H+NzLLpI0EhjZ7f1k9XAR54R9hpAb\nmAGMZ/7K59WAPwPbAAsBDwF7mNlTRfvyymfnSoiNRMxzCa6ULCqfu8XMPpd0IGGyj57ABWb2tKT9\n4/pzzGyKpDHAZEIntPOKEwXnXHne+shlIbMcQy15jsG1u1iXsIqZPZl3LK55dDXHUHGiHkkLSLq7\n62E557orjlU2Hm9t5OqkYlFSLA6aI6mfmb1br6C6Q6I/sBYwMO9YnOuOUi2O8o3ItYs0dQwfAo9L\nuiO+hlDZdXB2YXWNxEBgHKFp7SfArflG5FzXSFobuITQks9bHLm66rSOQdI+8WVhQxEShr9lGFdx\nDJ2Wk0ksAtwJjDPjV/WJzLlsSNoUWAHvl+C6oat1DKkqnyUtROhmDzDFzD6r9kDdUe7kJJYHDiMk\nVusS+j/sa4a31HDOtb3MmqvGDhN/I0zSA7CspO+bWaXhMOplPcIc1OcSKucu80TBOee6J00dwynA\n1mb2DEAcO+lKwlAWjeAFs8afUc65UmKLo5FmdlresThXULG5arRAIVEAMLNnybBjnHPtIM69fAxw\nOzAz73icS0pzg39U0vnA3wll+XsRRnF0znVBzCVcjLc4cg0qTY7hAMIcCgcDBwFPxvecc1WStCsh\nl3AKsKMnCq4RNe2QGBILAjcDD5nxu3wic646kgYCC3mC4Ooh0+aqeSs+OYkehKKthYHdzPg8t+Cc\nc65BNdzoqhk7GhgCbOOJgmtUknqmnLvEuYaSpo4BAEmLZBlIlTYBjjXjo7wDca5YosXRjXnH4lxX\ndJowSNpY0lOESXeQtK6kRug30PhlYK7tJEZCXQ/4cc7hONclaXIMpwGjgLcAzOwxYLMsg3Ku2RT1\nS/AWR66ppapjMLNpUof6Cy/Xd66j3fC5l12LSJMwTJO0CcwdH/5gQr8G59w8lwOX+0iorhWk7eD2\nM2Aw8CowLC475yKL8o7DuVpIk2NY1cy+k3wj5iDuyyYk5xpXzDWvaWYT8o7FuaykyTH8OeV7zrU0\nn3vZtYuyOQZJXwU2Br4k6ZeEAfQA+lBF/wfnmp3PvezaTaWipAUJiUDP+LtgFvCtLINyrlFIWouQ\nEPhIqK5tlE0Y4gxt90i62Mym1i8k5xpKT0K/BJ972bWNNJXPsyWdDKxBGLQOQiOMLbILy7nGEDt0\nPpZ3HM7VU5q6gsuAKcCKwGhgKj5Rj3POtaw0CcNAMzsf+NTM7jGzfQHPLbiWEscA83k9nCNdwvBp\n/P26pB0kDQf6ZxiTc3VTNMbRy3nH41wjSFPHcJykfsAhwJlAX+AXmUblXB343MvOldZpwmBmN8WX\n7wIjASSNyDAm5zInaXvgImK/BG9x5Nw8lTq49QD+B1gJeMLMbpW0PnA8sCSwbn1CdC4T9+K5BOdK\nqpRjOBdYgTAEwG8l/RBYjdAD9IY6xOZcZszsfeD9vONwrhFVShg2AtY2szmSegOvAyuZ2cz6hOZc\nbUjqZWaf5R2Hc82iUsLwmZnNATCzjyW9lGeiINET2IUwVMegvOJwzSMxxtFISSO9HsG5dColDKtJ\nejyxvFJi2cxs7QzjKmV5QmXhDcCjhE53zpVU1OJoT08UnEuvUsKwet2iSEfA62bslXcgrnGVGgnV\nEwXnqlNpEL2p3d25pFHAaYSByM43sxPLbLcB8ACwu5ld193jura2DT73snPdktm8CpJ6Eib0GUUY\ngG9PSfPlQuJ2JwJjmDfng3NddTOwoycKznVdlhPujACeN7OpsUXIlcDOJbY7CLgGeDPDWFyb8LmX\nneu+VAmDpEUkDa1y34OBVxLL0+N7yf0OJiQWZ8W3/AvtUoljHG2cdxzOtaJOEwZJOwETgdvi8jBJ\nN6bYd5qb/GnAr+MTnvCiJJdCYu7lX0jy/xnnaizNIHqjgQ2BuwHMbKKkFVN87lVgmcTyMoRcQ9J6\nwJXxu70EsK2kz8ysRMKz/MGw+wDppNHAWDMbmyIG10K8xZFzlUkaSRzTrlv76ex7JekhM9tQ0kQz\nGxbfm9xZPwZJCwDPAFsCMwhPeHua2dNltr8IuKlUqyRJBrYKMMaMldOcmGstktYALic8XOznlcvO\ndU6SmVnVueo0OYYnJe0FLCBpFeBg4P7OPmRmn0s6kFAE1RO4wMyelrR/XH9OtcG6tvYpPveyc3WR\nJsewKCH7vnV86zbgWDP7OOPYkjF4jsE556rU1RxDmoRhuJlN6HJkNeAJg3POVa+rCUOa5qqnSJoi\n6VhJa3YhNudSi3Mvn+StjZzLT6cJg5mNBDYH3gLOkfS4T5ruaq1o7uXHO9veOZedVB3czOw1Mzsd\n+AkwCTgq06hcW0n0SyiMcXSJVzA7l580HdzWkDRa0hOEsY/up6gHc518N4djuoxJ2pKQSzgFH+PI\nuYaQprnqhYRxjrYxs1czjqeSJYEzcjy+y8Z/8JFQnWsonbZKagRdrVl3zrl2VvMObpKuNrPdimZx\nK8hjBjfX5CT1rmf/F+dc15TNMUha2sxmSFqO+Qe3MzN7OfPo5sXiOYYmlhjjaHtgA69Ydq4+at6P\nIVHm+9M4p8LcH+CnXYzTtZmiFkc7eaLgXONL01x16xLvbVfrQFxrKeqX4C2OnGsileoYDiDkDFYq\nqmfoA9yXdWCu6X0VGI63OHKu6VSqY1gc6A/8H3A48+oZ3jezmfUJb24sXsfgnHNVqvkgepL6mtks\nSQMpMRubmb1dfZhd4wmDc85VL4uE4RYz217SVEonDCtUHWUXecLQuGKLo03N7M68Y3HOdZTZsNuN\nwBOGxhRbHF0MvATsamZz8o3IOZeU2bDbkjaRtFh8/T1Jp8S+Da5NlWhxtIsnCs61jjTNVc8GZkta\nB/gl8CJwSaZRuYYlaTV8JFTnWlqahOHz+DT4TeAvZvZnQpNV155mAX/C+yU417LSjK76vqQjCcNe\nbyqpJ9Ar27Bco4qJwaV5x+Gcy06aHMMewCfAD8zsdcJcDCdlGpVzzrncpGqVJGkpYANCs9XxZvbf\nrAMrOr63Sqqz2OLoJ4Sxsrxi2bkmlGWrpN2Bh4DdgN2B8ZJ2qz5E1wyKWhzdT4k+LM651tZpjkHS\nZGCrQi5B0peAO+s5H4PnGOoj0S9hOrCfVy4719wyyzEQxkh6M7E8k/nnZ3BNTtLG+EiozjnStUoa\nA9wm6XLBnW6+AAAW3klEQVRCgrAH8K9Mo3J5eAhYOzYwcM61sbSVz7sAX4uL48zs+kyjmv/4XpTk\nnHNVymLO51UJzVJXBiYDh5nZ9K6H6BqFpEXN7MO843DONaZKdQwXAjcDuwITgDPqEpHLTKLF0fjY\nUdE55+ZTqY5hMTM7L76eImliPQJy2ShqcfQNM/si34icc42qUsLQW9Lw+FrAwnFZgJnZhMyjc90W\n50v4DXAAcChwqQ9655yrpNJEPWPp2LlJyWUz2zzTyDrG4pXPXSRpPeAo4ABvgupce/GJepxzznWQ\nZQc355xzbcQThhYRWxztkHcczrnm5wlDC4gtjsYD+0lK05vdOefKSjO6ao841/NRcXlZSSPSHkDS\nKElTJD0n6fAS6/eSNEnSZEn3Sarb4HzNrsTcyzub2ec5h+Wca3JpRlc9G5gDbGFmq0kaANxuZut3\nuvPQieoZYCvgVeBhYE8zezqxzVeBp8zsPUmjgNFmtlHRfrzyuYiklYFr8JFQnXNl1HxIjIQNzWxY\noYObmb0tKe3UniOA581sagzySmBnYG7CYGYPJLZ/CBiSct/tbibwR+AK75fgnKulNHUMnyaHT4jz\nMaSd0Wsw8EpieXp8r5wfArem3HdbM7N3zOxyTxScc7WWJsdwJnA9sKSk44FvAb9Nuf/UNy1JmwM/\nADYps350YnGsmY1Nu2/nnGsHkkYCI7u9n5TDbq8ObBkX70zWEXTyuY0IdQaj4vIRwBwzO7Fou7WB\n64BRZvZ8if20bR1DbHF0KLCvmX2WdzzOueaR5ZzPywIfAjfFnw/je2k8Aqwiafk4Zs8ewI0l9n8d\n8N1SiUK7KmpxdDvgrY2cc3WRpijpVuYVCfUGViC0NPpKZx80s88lHQjcBvQELjCzpyXtH9efQxjH\npz9wliSAz8wsdXPYVlQ0Euq63uLIOVdPVY+VFEdY/ZmZ/TCbkEoes22KkiQNIySkPhKqc65b6jqI\nnqQnzGzNqj/YRW2WMAhYwszezDsW51xzy6wfg6RDEos9gOGEzmouAzGH4ImCcy43aeoYFku8/pww\n3ee12YTTXiQtbmbv5R2Hc84lVUwYYse2vmZ2SKXtXHUSs6p9V9LqZvZp3jE551xB2eaqkhaI8wJv\nEsu9XQ3EyuWHgfWATT1RcM41mko5hvGE+oTHgBskXQ3MjuvMzK7LOrhWUjT38iHA373FkXOuEVVK\nGAq5hN6EAdu2KFrvCUN1VgLWxPslOOcaXNnmqpKmE8b4L1mMZGZ/yjCu4ljaprmqc87VShbNVXsC\nfboeknPOuWZUKccw0cyG1TmekpopxxDrEnY2s6vzjsU5194yG0TPpZdocbS3pIXyjsc557qiUo5h\noJnNrHM8JTV6jsFbHNWPJL+uzpVQ6h5Z8zqGRkkUGp2kFYB/AtPwFkd10cgPCc7lodYPTF0aRK/e\nGjnHIGlRYAfgKs8lZK+R/xecy0u570VdR1etN78ZuAL/X3BufrVOGLzy2TnnXAeeMKQkaZik6yT1\nzjsW55zLkicMnUjMvXwbcD3wSc4hOdcUJK0h6eG842gFkq6RNKpex/OEoYJEv4ThhBZHPtWmK0vS\nVEmzJb0v6XVJl0rqW7TNxpLukjRL0ruSbpS0etE2fSWdJunluK/nJZ0qaWB9z6jbjgVOyjuI7pC0\nvKS7JX0o6WlJW1bYdgFJZ0p6TdLM+LddOrF+Y0nj499+kqRNEuuWitu/KmmOpGWLdn8i8Ifan2Fp\nnjCUIWkoIZdwMrCTN0N1KRiwg5n1AdYB1gJ+W1gp6avMy3kOAlYAJgH3xWbPhT4xdwKrA9vEfX0V\neAsYkVXgktJM2lXN/gYBIwlNubvy+Z61jKcbrgAeBQYQ+ipdI2mJMtv+FNgUWBtYGngHOBNA0gDg\nJsINfnHgj8BNkvrFz84BbgV2LbVjM3sY6CtpvRqcU+fMrOF/iDNe5nDc/nmfu/80xv9CytheArZI\nLP8RuCWxPA74c4nP3Qr8Lb7+EfA6sEgVx/0KcAdhFOTXgV/H9y8Gjk1sNxJ4JbE8FfgVMBn4OL6+\numjfpwOnx9eLAxcAM4DphBxBjzIx7Q3cXvTer4HngVnAk8A3E+v2Ae4jDNz5FvB7YEHCg9nL8bzO\nAnrH7fsRZpP8L/A24aY7uMZ/z1XjdVk08d49wP5ltj8HODGxvD0wJb7eAXiyaPtngB8UvbcAIZFY\ntsT+zwWOquZ70dXvi+cYKjCzd/KOwTUdAUgaAowCHorLixCe/EuNoXUV8I34eivgX2Y2u8R28x9M\n6gP8m5C4DAJWJuQ4IORgOiv6/DawLeGmfyWwnaTF4r57ArsBl8VtLwY+JQwhPwzYmpCQlbIW4caX\n9DzwNTPrCxwD/F3SlxPrRwAvAEsCxxOerlcm5L5WBgYDR8VtexASqWXjz0fAn8udpKSbJb1T5ufG\nMh/7CvCimX2YeG9SfL+U24FtJQ2Kf++9CH+XcnpU2FcpTxOuReY8YSAM/5F3DK42JKwWP109PPBP\nSbMIPeFfYF658ADC9+21Ep97HSgUTwwss005OwAzzOxUM/vUzD6wUOyQjKkcA84ws1fN7BMzmwZM\nAP4nrt8CmG1m4+MNfFvgF2b2kZm9CZxGSFhKWRz4oMPBzK4xs9fj66uA54ANE5vMMLO/mNkcQiOP\nHwO/NLN3zewD4ITC8czsbTO73sw+juuOBzYre6JmO5hZ/zI/O5X52GJA8Zzssygz6rSZXQtMBF6N\nnxtKyFUBPAAMkrSHpF6Svg+sCCxSLuYSPiDklDLX1glDosXRxJjCuyZnhmrx09XDE0bW7UsottkC\nWD+ue4dQRDCoxOcGAW/G128RyqfTWgZ4sSvBRq8ULV8O7Blff4d5uYXlgF7Aa4UnbeBs4Etl9vsO\nRTdQSXtLmpj4/JqEhLBULF8i3DQfTWz/L2ICKmkRSefECv/3CEU8i0s1nYb4A6Bv0Xv9CInDfCSd\nTDjnAcCihLqkf8HcIYa+SRhL7XVgG0JOb3oV8fQB3q1i+y5r24ShqMXRRmmz7s6lYWb3EioeT4zL\nHxKeGncvsfnuzCv++TewTRUPKtMIT56lfEjHJ9KlSoVatHwNMFLSYMKN7PL4/iuEp/iBiSftxc1s\nrTLHnkwoowdA0nKEMvKfAQPMrD/wBB1zNMlY3iIUD62ROF6/mOhCuMGuCowws8UJuQVRJock6V+x\nhVepn1vKnMOTwIqForVonfh+KaOAi2IO51NC0daIWPGMmd1rZiPMbCChDmY1whTKaa1OmGo5c22X\nMBT1S/AWRy5LpxFuDIXikl8D35d0kKQ+kvpL+gOhOOWYuM2lhJvwtZKGSuohaaCkIyVtW+IYNxOK\nKH4uaaG430LrpccIdQb9JS0F/G9nAcciorGE+oQXzeyZ+P5rhDL0U+IxekhaSdLXy+zq38Dw2MoK\nwhO0EW74PSTtS8gxlItjDnAecJqkLwFIGixp67jJYoSE47144z26k/Pa1sz6lPnZvsxnniVcw6Ml\n9Za0S4z52jKHmUz4+/aV1IvQSulVM3s7xj8sFiP1Jdx7ppnZHYUPK3SeLXSg7a35O9N+nZgDyVrb\nJQyEbPtqeL8ElzEzewv4G3B4XL6PUISwC6Flz1TCE+jXzOyFuM2nhAroKYSWRu8RKrAHAA+WOMYH\nhIrrHQl1E88SirEgJDKT4nHGECqX0/y/Xw5sybzcQsHehJZCTxFaAl1N6VwIZvYGcBch14GZPQX8\niZBrep1wg/1P8iMlYjucUGH9YCwuuoN5uZDTgIUJCc39hBtmFt/lbxOKA98GjgN2jcVCSNpU0vuJ\nbX9BKC58gdBaahTz6msADiMUGU4Dvly0DmA2oZjKCH//uZXekjYA3jezR2p2ZhX4IHquqfj/QvNQ\n6Lj3NzPLrP9Fu5B0DXC+mY0ps77k96Kr3xdPGFxT8f8F5+ZX64ShZYuSYl3C92vcSsE551peSyYM\niRZH36K6dsLOOdf2WiphKNPi6MNOPuaccy6hpgNn5SkOQXALPveyc851S8tUPsf20jsA13sT1Nbl\nlc/Ozc9bJbm2Jqnx/2Gdy0EtE4ZMi5IUZhw6DehJaIN7YoltziAMzjUb2MfMJmYZk2tu/oDgXPYy\nq3yOQ/b+mdD7bw1gT80/U9V2wMpmtgqwH2G89c72OyyOe1I8uFVbkDQy7xgahV+LefxazOPXovuy\nbJU0AnjezKaa2WeE7vg7F22zE2HIAMzsIaBf0fjscxW1OLoceL/Udm1gZN4BNJCReQfQQEbmHUAD\nGZl3AM0uy6KkwXQcRnc6HcdeL7fNEOCNEvt7GG9x5JxzmcsyYUhbSVhcZlzuc38CfNA755zLWGat\nkiRtBIw2s1Fx+QhgTrICWtLZwFgzuzIuTwE2iyMzJvfliYFzznVBo7VKegRYRdLyhCGG92DezFAF\nNwIHAlfGhOTd4kQBvCWKc87VU2YJg5l9LulAQmVxT+ACM3ta0v5x/Tlmdquk7SQ9Txh7fN+s4nHO\nOZdOU3Rwc845Vz8NNYiepFGSpkh6TtLhZbY5I66fFEdRbUmdXQtJe8VrMFnSfZLWziPOekjzfxG3\n20DS53EKxpaT8vsxUtJESU9IGlvnEOsmxfdjCUljJD0Wr8U+OYRZF5IulPSGpMcrbFPdfdPMGuKH\nUNz0PLA80Isw1+rqRdtsB9waX28IPJh33Dlei68Ci8fXo9r5WiS2u4swB/Kueced0/9EP8JE9UPi\n8hJ5x53jtRgNnFC4DsBMYIG8Y8/oemwKDAMeL7O+6vtmI+UYatohrsl1ei3M7AEzey8uPkTo/9GK\n0vxfABwEXEOYU7cVpbkO3wGuNbPpMHfO6VaU5lq8BhRGR+gLzDSzz+sYY92Y2TjgnQqbVH3fbKSE\noVRnt8EptmnFG2Kaa5H0Q+DWTCPKT6fXQtJgwo2hMKRKK1acpfmfWAUYIOluSY9I+l7doquvNNfi\nPOArkmYAk4Cf1ym2RlT1fbOR5mOodYe4Zpb6nCRtDvwA2CS7cHKV5lqcBvzazCxO5dqKzZvTXIde\nwHBgS8LMhQ9IetDMnss0svpLcy2OBB4zs5GSVgLukLSOmbXrUDpV3TcbKWF4FVgmsbwMIWWrtM2Q\n+F6rSXMtiBXO5wGjzKxSVrKZpbkW6xH6wkAoT95W0mdmdmN9QqyLNNfhFeAtM/sI+EjSvcA6QKsl\nDGmuxcbAcQBm9oKkl4ChhP5V7abq+2YjFSXN7RAXJ93Zg9ABLulGYG+Y27O6ZIe4FtDptZC0LHAd\n8F0zez6HGOul02thZiua2QpmtgKhnuGAFksUIN334wbga5J6SlqEUNH4VJ3jrIc012IKsBVALE8f\nCrxY1ygbR9X3zYbJMZh3iJsrzbUAjgL6A2fFJ+XPzGxEXjFnJeW1aHkpvx9TJI0BJgNzgPPMrOUS\nhpT/E8cDF0maRHgA/pWZvZ1b0BmSdAWwGbCEpFeAownFil2+b3oHN+eccx00UlGSc865BuAJg3PO\nuQ48YXDOOdeBJwzOOec68ITBOedcB54wOOec68AThjYh6Ys4HHPhZ9kK235Qg+NdLOnFeKxHY8ea\navdxnqTV4usji9bd190Y434K12WypOskLdbJ9utI2rYWx04Z378l9YmvOx1euZN97SBpQhyK+klJ\n+9U41mMkbRlfbxqPMUHS0pKuju+nun6SDm7hsZ4anvdjaBOS3jezPrXetsI+LgJuMrPrJH0DONnM\n1unG/rodU2f7lXQxYejiP1XYfh9gPTM7qMZxLFA8+qekLQhDiP8sLm8KfABcYmZrVbn/XsBUYAMz\nmxGXVzCzZ2tyAvMf72xgnJldVvT+PqS4fjExvLMVO202A88xtClJi8an0Ufj0/JOJbYZJOne+ET9\nuKSvxfe3lnR//OxVkhYtd5j4exywcvzsL+O+Hpf080Qst8Qn2ccl7RbfHytpPUn/Bywc47g0rvsg\n/r5S0naJmC+WtIukHpJOkjReYXKSNE/HDwArxf2MiOc4QWEipFXj8Au/B/aIsewWY79Q0kNx2/mu\nY9zfSfHcJkvaPb43UtI4STcQ5lEo9h3CMBdAquGVK+lDGOng7bivzwqJQrxmZ0t6WNIzkraP7/cs\ndw0lHR7P5TFJxyf2s6ukHwK7AcdKulTScvHceyWu3wRJu0t6VtIS8fM9JD0vaWAc7G6mpK908Xxd\nd+Q9yYT/1OcH+ByYGH+uJQwl0CeuWwJ4LrHt+/H3IcCR8XUPYLG47T3AwvH9w4HflTjeRcQJcwg3\niQcII39OBhYGFgWeANYFdgXOTXy2b/x9NzA8GVOJGL8JXBxfLwhMAxYC9gN+E99fCHgYWL5EnIX9\n9IzX5adxuQ/QM77eCrgmvv4+cEbi88cDe8XX/YBngEWKjrErcDshoVwSeBlYChhJyAEsV+Zv9jQw\noOi95SkzIUuK/4HzgDeAywmJTqHE4CLmTeSyMmEwvrLXENgWuA/oXTjvxH52KfF6bswlrt9RwM/j\n662BqxPrjiGMe5X796fdfhpmrCSXuY/MbO6UfvHp7YRYPDEHWFrSkmb238RnxgMXxm3/aWaTJI0E\n1gDuVxijaUHg/hLHE3CSpN8C/yXMGfEN4DoLo38i6TrC7FNjgJNjzuBmM/tPFec1Bjg9Ps1vC9xj\nZp9I2hpYS9K34nZ9CTe9qUWfX1jSRMKY9VOBs+P7/YBLJK1MGKK48F0pHtZ7a2BHSYfG5YUII1k+\nk9hmE+ByC3e7/0q6B9gAmAWMN7OXy5zb0lbD8X3M7MeSTickdIcS/h6FcXOuits8L+lFYLV4bsXX\ncBXCsN4XmtnH8TPvljlkqeHPi6/fhYRc0emE4eMvSqybAaxYzTm62vCEoX3tRXj6H25mXygMS9w7\nuYGZjYsJxw7AxZJOIRRl3GFm3+lk/wYcambXFd6QtBUdbwoKh7HnFOah3R74g6Q7zezYNCdhZh8r\nzG28DbA7cEVi9YFmdkcnu/jIzIZJWpgwKNvOwPXAsYQy7v+RtBwwtsI+drHO5zwoNx7+h518LjVJ\nPZk3rPQNZja6eBszewJ4IhbJvUT5AdUK8c13DSVtQ43mvDCz6QoV6lsQEss9k4ci3dwLrsa8jqF9\n9QX+GxOFzYHlijdQaLn0ppmdD5xPmFf2QWAThclPCvUDq5Q5RvHNYxzwTUkLx3qJbwLjJA0CPrZQ\nUXlyPE6xzySVe5D5B+Fps5D7gHCT/2nhM7GOYJEynyfmYg4GjlPICvUlPLFCx5vnLEIxU8Ft8XPE\n45SKfRyhXL2HpC8BXyfkxjq7uc6QNLCTbZLn8IWZDYs/o5Pr4t9pZOKtYczLPQnYTcFKhKf0KZS/\nhncA+8bEFEn908bI/NcPwv/W34GrYq6qYBDz5/BcHXjC0D6Kn7wuA9aXNBn4HqE8u3jbzYHHJE0g\nPI2fbmEe4X2AKxSGNL6fMNZ9p8c0s4nAxYSb4oOEYaEnAWsBD8UinaOAP5TY17nA5ELlc9G+byfc\nbO+weS17zifMRTBBoXnnWZTOIc/dj5k9Rphkfnfgj4SitgmE+ofCdncDaxQqnwk5i16xIvYJQrl4\nxwOYXU+oW5kE3AkcFovsrPgaFfkPsH5hQWF45fuBVSW9IqmaYecFHCZpSrzORxP+joVrMI3wd7kV\n2N/MPqX0NexpZrcRxvh/JO7rkDLHtBKvk9dv9/jeTYQ6p2QxEoS5ncdVcY6uRry5qnMNKj7h72Fm\nB2R8nLlNi7M8ToXjrw/8ycw2S7zXl1CUt0EeMbU7zzE416DMbCxhprKa999oFJJ+TZh174iiVfsQ\nKqRdDjzH4JxzrgPPMTjnnOvAEwbnnHMdeMLgnHOuA08YnHPOdeAJg3POuQ48YXDOOdfB/wMd+vNw\nGYwKpwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x109a1d390>"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "{'clf__max_depth': 3, 'clf__max_features': 0.5, 'imp__strategy': 'median'}"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this search we can conclude that the imputation by the 'mean' strategy is generally a slightly better imputation strategy when training a GBRT model on this data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Further integrating sklearn and pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper tool for better sklearn / pandas integration: https://github.com/paulgb/sklearn-pandas by making it possible to embed the feature construction from the raw dataframe directly inside a pipeline."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Credits"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Thanks to:\n",
      "\n",
      "- Kaggle for setting up the Titanic challenge.\n",
      "\n",
      "- This blog post by Philippe Adjiman for inspiration:\n",
      "\n",
      "http://www.philippeadjiman.com/blog/2013/09/12/a-data-science-exploration-from-the-titanic-in-r/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    }
   ],
   "metadata": {}
  }
 ]
}
